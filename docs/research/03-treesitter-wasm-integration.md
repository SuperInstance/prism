# Tree-sitter + WASM Integration Research for Vantage

**Research Date**: 2026-01-13
**Researcher**: Claude (AI Research Agent)
**Status**: Final
**Project**: Vantage v0.1.0

## Executive Summary

This research document provides comprehensive findings on integrating Tree-sitter with WebAssembly (WASM) for the Vantage project's codebase indexing needs. Vantage requires indexing 100K+ LOC in seconds with support for TypeScript, JavaScript, Python, Rust, Go, and Java in mixed-language repositories.

**Key Findings:**
- Tree-sitter has excellent grammar support for all target languages
- WASM performance is ~45% slower than native but still 10x faster than JavaScript parsers
- Incremental parsing is the key optimization strategy (not parallel parsing)
- Code chunking at 512 tokens is the industry best practice for vector embeddings
- Memory management is critical; WASM leaks are common without proper cleanup

**Recommendation:** Proceed with Rust + Tree-sitter compiled to WASM using wasm-pack, with focus on incremental parsing and proper memory management.

---

## 1. Tree-sitter Language Support

### 1.1 Language Grammar Quality

All priority languages for Vantage have excellent Tree-sitter grammar support:

| Language | Grammar Status | Version | Quality Assessment |
|----------|---------------|---------|-------------------|
| **TypeScript** | ✅ Excellent | tree-sitter-typescript v0.23.2 | Production-ready, used by VS Code |
| **JavaScript** | ✅ Excellent | tree-sitter-javascript v0.25.0 | Battle-tested, wide adoption |
| **Python** | ✅ Excellent | Official grammar maintained | Robust error recovery |
| **Rust** | ✅ Excellent | Official grammar maintained | Handles complex syntax well |
| **Go** | ✅ Excellent | Includes go-mod support | Production-ready |
| **Java** | ✅ Excellent | Mature grammar | Widely deployed |

**Additional Supported Languages:**
- C, C++, C#
- Ruby, PHP
- Bash, PowerShell
- YAML, JSON, HTML, CSS
- Dart, Kotlin, Swift

### 1.2 Mixed-Language Repositories (Monorepos)

Tree-sitter handles mixed-language codebases through:

**Language Injection:**
```javascript
// Example: JavaScript file with embedded SQL
const query = sql`SELECT * FROM users`; // Tree-sitter can parse both JS and SQL
```

**Implementation Strategies:**

1. **Per-File Detection**: Use file extensions to select parser
   ```rust
   fn get_parser(file_path: &str) -> Option<Parser> {
       match Path::new(file_path).extension()?.to_str()? {
           "ts" | "tsx" => Some(create_typescript_parser()),
           "js" | "jsx" => Some(create_javascript_parser()),
           "py" => Some(create_python_parser()),
           "rs" => Some(create_rust_parser()),
           "go" => Some(create_go_parser()),
           "java" => Some(create_java_parser()),
           _ => None,
       }
   }
   ```

2. **Language Injection for Embedded Code**: Tree-sitter supports nested languages
   - JSX/TSX with embedded expressions
   - JavaScript with template literals containing SQL, HTML, etc.
   - Markdown with code fences

3. **Unified Parse Tree**: Some tools maintain a single parse tree across languages
   - PolyglotPiranha uses this approach for multi-language code transformation

**Best Practices for Monorepos:**
- Store language metadata in a `tree-sitter.json` configuration file
- Use the `tree-sitter-config` crate for configuration management
- Implement a language registry pattern for dynamic parser loading

### 1.3 Language-Specific Parsing Challenges

**TypeScript/JavaScript:**
- Challenge: JSX/TSX syntax complexity
- Solution: Use `tree-sitter-typescript` which handles both TypeScript and TSX
- Challenge: Dynamic typing and type inference
- Solution: Focus on structural parsing, not semantic analysis

**Python:**
- Challenge: Indentation-based syntax
- Solution: Tree-sitter handles this natively
- Challenge: Decorators and context managers
- Solution: Grammar supports these constructs well

**Rust:**
- Challenge: Macros and procedural macros
- Solution: Parse structurally; don't expand macros
- Challenge: Lifetimes and generics
- Solution: Grammar handles these, but may need custom queries

**Go:**
- Challenge: Goroutines and channels
- Solution: Grammar supports these constructs
- Challenge: Go modules
- Solution: Use `go-mod` grammar for module files

**Java:**
- Challenge: Annotations and generics
- Solution: Grammar supports these well
- Challenge: Lambda expressions
- Solution: Modern Java grammar handles lambdas

---

## 2. WASM Integration Patterns

### 2.1 Best Practices for Compiling Tree-sitter to WASM

**Recommended Toolchain:**

1. **wasm-pack** (Primary choice)
   ```bash
   # Standard build command
   wasm-pack build --target web
   ```

2. **wasm-bindgen** (for JavaScript interop)
   - Provides high-level interactions between WASM and JavaScript
   - Generates JavaScript bindings automatically

3. **tree-sitter-wasm-build-tool** (Specialized crate)
   - Specifically designed for compiling tree-sitter parsers to `wasm32-unknown-unknown`
   - Works best with parsers that don't use certain advanced features

**Build Configuration:**

```toml
# Cargo.toml
[package]
name = "vantage-indexer"
version = "0.1.0"
edition = "2021"

[lib]
crate-type = ["cdylib", "rlib"]

[dependencies]
tree-sitter = "0.25"
tree-sitter-typescript = "0.23"
tree-sitter-javascript = "0.25"
tree-sitter-python = "0.25"
tree-sitter-rust = "0.25"
tree-sitter-go = "0.25"
tree-sitter-java = "0.25"
wasm-bindgen = "0.2"
serde = { version = "1.0", features = ["derive"] }
serde-wasm-bindgen = "0.6"

[profile.release]
opt-level = "z"  # Optimize for size
lto = true      # Link-time optimization
codegen-units = 1
```

**Target Specification:**
```bash
# Install WASM target
rustup target add wasm32-unknown-unknown

# Build
cargo build --release --target wasm32-unknown-unknown

# Or use wasm-pack
wasm-pack build --target web --release
```

### 2.2 Memory Management (Avoiding Leaks)

**Critical Issues:**

1. **WASM Memory Leaks from Long-Lived Closures**
   - Problem: Severe memory leaks causing browser freezing/OOM
   - Solution: Explicit cleanup of closures and event listeners

2. **Repeated WASM Module Instantiation**
   - Problem: Heap arrays grow without bounds
   - Solution: Instantiate once, reuse instances

**Best Practices:**

```rust
use wasm_bindgen::prelude::*;

#[wasm_bindgen]
pub struct VantageParser {
    parser: tree_sitter::Parser,
    // Add other fields
}

#[wasm_bindgen]
impl VantageParser {
    #[wasm_bindgen(constructor)]
    pub fn new(language: &str) -> Result<VantageParser, JsValue> {
        let mut parser = tree_sitter::Parser::new();
        let language = match language {
            "typescript" => tree_sitter_typescript::language_typescript(),
            "javascript" => tree_sitter_javascript::language_javascript(),
            // ... other languages
            _ => return Err(JsValue::from_str("Unsupported language")),
        };
        parser.set_language(&language).map_err(|e| {
            JsValue::from_str(&format!("Failed to set language: {:?}", e))
        })?;
        Ok(VantageParser { parser })
    }

    // Explicit cleanup
    #[wasm_bindgen]
    pub fn free(&mut self) {
        // Clean up resources
        // Note: Tree-sitter Parser doesn't have explicit cleanup,
        // but this is where you'd free other resources
    }
}
```

**JavaScript Side:**

```javascript
// Import the WASM module
import init, { VantageParser } from './vantage_indexer.js';

let parser = null;

async function initializeParser() {
    await init();
    parser = new VantageParser('typescript');
}

// Clean up when done
function cleanup() {
    if (parser) {
        parser.free();
        parser = null;
    }
}

// Don't create new parsers for each file
async function parseFile(code) {
    if (!parser) {
        await initializeParser();
    }
    return parser.parse(code);
}
```

**Memory Monitoring:**

```javascript
// Monitor WASM memory
function checkMemoryUsage() {
    if (performance.memory) {
        console.log('Memory usage:', {
            used: performance.memory.usedJSHeapSize,
            total: performance.memory.totalJSHeapSize,
            limit: performance.memory.jsHeapSizeLimit
        });
    }
}
```

### 2.3 Performance Benchmarks: WASM vs Native JS

**Key Findings:**

| Implementation | Performance vs Native | Notes |
|----------------|----------------------|-------|
| **Native Tree-sitter (C/Rust)** | Baseline (100%) | Fastest |
| **WASM Tree-sitter** | ~45% slower on average | Still 10x faster than JS parsers |
| **JavaScript Parsers** | 10x slower than WASM | Babel, ESLint, etc. |
| **Best Case WASM** | 10-20% slower than native | For specific algorithms |

**Specific Benchmarks:**

1. **Large File Parsing (1.6MB JSON)**
   - Full parse: ~1.2s
   - Incremental reparse: ~0.7s (40-50% faster)

2. **WASM vs Native (SPEC CPU benchmarks)**
   - Average: 45% slower
   - Computational workloads: 2-5x improvements over JavaScript
   - Industry benchmarks: 1.75x improvements over JS

3. **Real-world Performance**
   - Tree-sitter WASM: "One of the main success stories of WebAssembly"
   - Fast enough for real-time syntax highlighting
   - Can parse on every keystroke

**Recommendation for Vantage:**
- Use WASM for cross-platform compatibility
- Expect ~45% performance penalty vs native
- Still significantly faster than pure JavaScript parsers
- Focus on incremental parsing to mitigate performance differences

### 2.4 Tooling Comparison

| Tool | Pros | Cons | Recommendation |
|------|------|------|----------------|
| **wasm-pack** | Easy to use, generates bindings, well-documented | Limited to Rust | ✅ **Primary choice** |
| **wasm-bindgen** | Fine-grained control, TypeScript support | More complex setup | ✅ Use with wasm-pack |
| **Custom build** | Maximum control | Complex, error-prone | ❌ Not recommended |

**Build Workflow:**

```bash
# Development build (faster, less optimized)
wasm-pack build --dev --target web

# Production build (optimized)
wasm-pack build --release --target web

# Test in Node.js
wasm-pack build --target nodejs

# Test in bundlers
wasm-pack build --target bundler
```

---

## 3. AST Extraction Strategies

### 3.1 Extracting Functions, Classes, Methods Efficiently

**Using Tree-sitter Queries:**

Tree-sitter queries are the most efficient way to extract code elements:

```rust
use tree_sitter::Query;

// Define queries for different languages
const TYPESCRIPT_FUNCTION_QUERY: &str = r#"
(function_declaration
  name: (identifier) @function.name
  parameters: (formal_parameters
    (identifier) @param.name)*
  body: (statement_block) @function.body) @function.definition

(method_definition
  name: (property_identifier) @method.name
  parameters: (formal_parameters
    (identifier) @param.name)*
  body: (statement_block) @method.body) @method.definition

(class_declaration
  name: (type_identifier) @class.name
  body: (class_body
    (method_definition)* @class.methods)) @class.definition
"#;

#[wasm_bindgen]
pub struct CodeExtractor {
    query: Query,
}

#[wasm_bindgen]
impl CodeExtractor {
    pub fn extract_functions(&self, source: &str) -> Vec<FunctionInfo> {
        let mut parser = tree_sitter::Parser::new();
        parser.set_language(&tree_sitter_typescript::language_typescript())
            .unwrap();

        let tree = parser.parse(source, None).unwrap();
        let root = tree.root_node();

        let mut cursor = tree_sitter::QueryCursor::new();
        let matches = cursor.matches(&self.query, root, source.as_bytes());

        let mut functions = Vec::new();
        for m in matches {
            for capture in m.captures {
                let node = capture.node;
                let text = &source[node.byte_range()];
                // Extract function info
            }
        }
        functions
    }
}
```

**Function-Level Extraction Pattern:**

```rust
#[derive(Serialize, Deserialize)]
pub struct FunctionInfo {
    pub name: String,
    pub signature: String,
    pub start_line: usize,
    pub end_line: usize,
    pub start_byte: usize,
    pub end_byte: usize,
    pub parameters: Vec<String>,
    pub return_type: Option<String>,
    pub is_async: bool,
    pub is_exported: bool,
}

pub fn extract_function_info(
    node: &tree_sitter::Node,
    source: &str
) -> Option<FunctionInfo> {
    let start_line = node.start_position().row + 1;
    let end_line = node.end_position().row + 1;
    let start_byte = node.start_byte();
    let end_byte = node.end_byte();

    let name = node.child_by_field_name("name")?
        .utf8_text(source.as_bytes()).ok()?;

    Some(FunctionInfo {
        name: name.to_string(),
        signature: extract_signature(node, source),
        start_line,
        end_line,
        start_byte,
        end_byte,
        parameters: extract_parameters(node, source),
        return_type: extract_return_type(node, source),
        is_async: node.child_by_field_name("async").is_some(),
        is_exported: is_exported(node),
    })
}
```

### 3.2 Preserving Line Numbers and Signatures

**Line Number Preservation:**

```rust
#[derive(Serialize, Deserialize)]
pub struct SourceLocation {
    pub start_row: usize,    // 0-indexed
    pub start_column: usize, // 0-indexed
    pub end_row: usize,
    pub end_column: usize,
}

pub fn get_location(node: &tree_sitter::Node) -> SourceLocation {
    let start = node.start_position();
    let end = node.end_position();

    SourceLocation {
        start_row: start.row,
        start_column: start.column,
        end_row: end.row,
        end_column: end.column,
    }
}
```

**Signature Extraction:**

```rust
pub fn extract_function_signature(
    node: &tree_sitter::Node,
    source: &str
) -> String {
    // Find the line containing the function signature
    let start_byte = node.start_byte();
    let end_byte = node.child_by_field_name("body")
        .map(|n| n.start_byte())
        .unwrap_or(node.end_byte());

    source[start_byte..end_byte].to_string()
}

// Better: Extract structured signature
pub fn extract_structured_signature(
    node: &tree_sitter::Node,
    source: &str
) -> StructuredSignature {
    let name_node = node.child_by_field_name("name");
    let params_node = node.child_by_field_name("parameters");
    let return_node = node.child_by_field_name("return_type");

    StructuredSignature {
        name: name_node
            .and_then(|n| n.utf8_text(source.as_bytes()).ok())
            .map(|s| s.to_string())
            .unwrap_or_default(),

        parameters: params_node
            .map(|n| extract_parameters(&n, source))
            .unwrap_or_default(),

        return_type: return_node
            .and_then(|n| n.utf8_text(source.as_bytes()).ok())
            .map(|s| s.to_string()),

        modifiers: extract_modifiers(node, source),
    }
}
```

### 3.3 Handling Syntax Errors Gracefully

**Tree-sitter's Error Recovery:**

Tree-sitter uses a novel error recovery strategy that:
- Does NOT fail on the first error
- Accepts any input string
- Attempts to correct errors to match the grammar
- Provides useful parse trees even with syntax errors

**Error Detection Pattern:**

```rust
pub fn parse_with_error_recovery(
    source: &str,
    language: &tree_sitter::Language
) -> ParseResult {
    let mut parser = tree_sitter::Parser::new();
    parser.set_language(language).unwrap();

    let tree = parser.parse(source, None).unwrap();
    let root = tree.root_node();

    // Check for error nodes
    let has_errors = root.has_error();
    let error_nodes = find_error_nodes(&root, source);

    ParseResult {
        tree,
        has_errors,
        error_nodes,
        // Still extract valid functions even with errors
        functions: extract_functions(&root, source),
    }
}

fn find_error_nodes(
    node: &tree_sitter::Node,
    source: &str
) -> Vec<ErrorInfo> {
    let mut errors = Vec::new();

    if node.is_error() || node.is_missing() {
        errors.push(ErrorInfo {
            message: "Syntax error".to_string(),
            location: get_location(node),
            text: source[node.byte_range()].to_string(),
        });
    }

    // Recursively check children
    let mut cursor = node.walk();
    for child in node.children(&mut cursor) {
        errors.extend(find_error_nodes(&child, source));
    }

    errors
}
```

**Best Practices for Error Handling:**
1. Always check `has_error()` on the root node
2. Extract valid code even when errors are present
3. Log error locations for debugging
4. Provide partial results rather than failing completely
5. Use error nodes to identify problematic code sections

### 3.4 Chunking Large Files into Semantic Units

**Semantic Chunking Strategy:**

```rust
pub fn chunk_file_semantically(
    source: &str,
    language: &tree_sitter::Language,
    max_tokens: usize
) -> Vec<CodeChunk> {
    let mut parser = tree_sitter::Parser::new();
    parser.set_language(language).unwrap();
    let tree = parser.parse(source, None).unwrap();
    let root = tree.root_node();

    let mut chunks = Vec::new();

    // Extract top-level functions and classes
    let mut cursor = tree_sitter::QueryCursor::new();
    let query = tree_sitter::Query::new(
        language,
        "(function_declaration) @func
         (class_declaration) @class
         (method_definition) @method"
    ).unwrap();

    let matches = cursor.matches(&query, &root, source.as_bytes());

    let mut current_chunk = CodeChunk::default();
    let mut current_tokens = 0;

    for m in matches {
        for capture in m.captures {
            let node = capture.node;
            let node_text = &source[node.byte_range()];
            let node_tokens = estimate_tokens(node_text);

            // Check if adding this node would exceed the limit
            if current_tokens + node_tokens > max_tokens && !current_chunk.is_empty() {
                chunks.push(current_chunk.clone());
                current_chunk = CodeChunk::default();
                current_tokens = 0;
            }

            // Add to current chunk
            current_chunk.nodes.push(node);
            current_tokens += node_tokens;
        }
    }

    if !current_chunk.is_empty() {
        chunks.push(current_chunk);
    }

    chunks
}
```

**Token Estimation:**

```rust
pub fn estimate_tokens(text: &str) -> usize {
    // Rough estimation: ~4 characters per token
    // For code, this is reasonably accurate
    text.len() / 4

    // Or use a more sophisticated method:
    // - Count keywords, identifiers, operators
    // - Account for language-specific syntax
}
```

---

## 4. Code Chunking Algorithms

### 4.1 Function-Level vs Block-Level vs Token-Based Chunking

**Comparison of Chunking Strategies:**

| Strategy | Pros | Cons | Best For |
|----------|------|------|----------|
| **Function-Level** | Semantic coherence, preserves meaning | Can be uneven sizes | Code search, RAG |
| **Block-Level** | More balanced sizes | May break semantics | General indexing |
| **Token-Based** | Precise control, fits embeddings | Loses semantic boundaries | Embedding generation |

**Recommended Approach for Vantage:**
1. **Primary**: Function-level chunking (semantic preservation)
2. **Fallback**: Token-based splitting for large functions
3. **Overlap**: Include context (imports, parent class info)

**Hybrid Chunking Algorithm:**

```rust
pub fn hybrid_chunking(
    source: &str,
    language: &tree_sitter::Language,
    target_tokens: usize,
    overlap_tokens: usize
) -> Vec<CodeChunk> {
    let mut chunks = Vec::new();

    // Step 1: Extract semantic units (functions, classes)
    let semantic_units = extract_semantic_units(source, language);

    // Step 2: Group into chunks
    let mut current_chunk = CodeChunk::default();
    let mut current_size = 0;

    for unit in semantic_units {
        let unit_size = estimate_tokens(&unit.text);

        // If single unit exceeds target, split it
        if unit_size > target_tokens {
            if !current_chunk.is_empty() {
                chunks.push(current_chunk);
                current_chunk = CodeChunk::default();
                current_size = 0;
            }

            // Split large unit
            let sub_chunks = split_large_unit(&unit, target_tokens, overlap_tokens);
            chunks.extend(sub_chunks);
            continue;
        }

        // Check if adding this unit would exceed limit
        if current_size + unit_size > target_tokens && !current_chunk.is_empty() {
            // Add overlap from previous chunk
            add_overlap(&mut current_chunk, overlap_tokens);
            chunks.push(current_chunk);
            current_chunk = CodeChunk::default();
            current_size = 0;
        }

        // Add unit to current chunk
        current_chunk.units.push(unit.clone());
        current_size += unit_size;
    }

    if !current_chunk.is_empty() {
        chunks.push(current_chunk);
    }

    chunks
}

fn split_large_unit(
    unit: &SemanticUnit,
    target_size: usize,
    overlap: usize
) -> Vec<CodeChunk> {
    // Parse the unit's AST
    // Split at logical boundaries (statements, expressions)
    // Add overlap between chunks

    // Implementation depends on language
    // For now, simple token-based splitting
    let text = &unit.text;
    let chunks = Vec::new();

    // TODO: Implement AST-aware splitting
    chunks
}
```

### 4.2 Preserving Import/Export Relationships

**Dependency Extraction:**

```rust
pub fn extract_imports(
    source: &str,
    language: &tree_sitter::Language
) -> Vec<ImportInfo> {
    let query = tree_sitter::Query::new(
        language,
        r#"
        (import_statement
            source: (string) @import.source)

        (import_statement
            (import_clause
                (named_imports
                    (import_specifier
                        name: (identifier) @import.name
                        alias: (identifier)? @import.alias))))

        (export_statement
            (export_clause
                (identifier) @export.name))
        "#
    ).unwrap();

    let mut parser = tree_sitter::Parser::new();
    parser.set_language(language).unwrap();
    let tree = parser.parse(source, None).unwrap();

    let mut cursor = tree_sitter::QueryCursor::new();
    let matches = cursor.matches(&query, &tree.root_node(), source.as_bytes());

    let mut imports = Vec::new();
    for m in matches {
        for capture in m.captures {
            // Extract import information
        }
    }

    imports
}

#[derive(Serialize, Deserialize)]
pub struct ImportInfo {
    pub source: String,
    pub imported_names: Vec<String>,
    pub is_type_only: bool,
    pub location: SourceLocation,
}
```

**Including Context in Chunks:**

```rust
pub fn add_import_context(
    chunk: &mut CodeChunk,
    imports: &[ImportInfo],
    referenced_imports: &[String]
) {
    // Add import statements for referenced symbols
    for import in imports {
        if referenced_imports.iter().any(|name| {
            import.imported_names.contains(name)
        }) {
            chunk.context.push(import.clone());
        }
    }
}
```

### 4.3 Handling Inline Functions and Closures

**Closure Detection:**

```rust
pub fn extract_closures(
    node: &tree_sitter::Node,
    source: &str
) -> Vec<ClosureInfo> {
    let mut closures = Vec::new();

    // Arrow functions
    let arrow_function_query = tree_sitter::Query::new(
        language,
        "(arrow_function) @closure"
    ).unwrap();

    // Anonymous functions
    let function_expression_query = tree_sitter::Query::new(
        language,
        "(function_expression) @closure"
    ).unwrap();

    // Extract closures
    // ...

    closures
}

#[derive(Serialize, Deserialize)]
pub struct ClosureInfo {
    pub parent_function: String,
    pub captured_variables: Vec<String>,
    pub location: SourceLocation,
    pub text: String,
}
```

**Chunking with Closures:**

```rust
pub fn chunk_with_closures(
    source: &str,
    language: &tree_sitter::Language
) -> Vec<CodeChunk> {
    // Strategy 1: Include closures with parent function
    // Strategy 2: Extract closures as separate chunks with context
    // Strategy 3: Create hierarchical chunks

    // Recommended: Strategy 1 for RAG
    // Include the closure within its parent function chunk
    // This preserves context and meaning
}
```

### 4.4 Best Chunk Size for Vector Embeddings

**Industry Consensus: 500-1000 Tokens**

| Use Case | Recommended Size | Overlap |
|----------|-----------------|---------|
| **Code Search** | 512 tokens | 128 tokens (25%) |
| **Documentation** | 1000-2000 tokens | 256 tokens |
| **Code Generation** | 500-800 tokens | 100 tokens |

**Recommendations for Vantage:**

1. **Baseline**: 512 tokens (industry standard)
2. **For functions**: Use function boundaries, max 1000 tokens
3. **For large functions**: Split at 512 tokens with 128-token overlap
4. **For classes**: Chunk methods individually, include class signature

**Implementation:**

```rust
pub const DEFAULT_CHUNK_SIZE: usize = 512;
pub const DEFAULT_OVERLAP: usize = 128;
pub const MAX_CHUNK_SIZE: usize = 1000;

#[derive(Serialize, Deserialize)]
pub struct ChunkConfig {
    pub target_size: usize,
    pub overlap: usize,
    pub max_size: usize,
}

impl Default for ChunkConfig {
    fn default() -> Self {
        ChunkConfig {
            target_size: DEFAULT_CHUNK_SIZE,
            overlap: DEFAULT_OVERLAP,
            max_size: MAX_CHUNK_SIZE,
        }
    }
}
```

**Why 512 Tokens?**
- Fits within most embedding model context windows
- Large enough to preserve semantic meaning
- Small enough for precise retrieval
- Balances recall and precision in RAG systems
- Industry-validated by multiple production systems

---

## 5. Performance Optimization

### 5.1 Parallel Parsing (Multiple Files at Once)

**Important Finding: Tree-sitter does NOT support native parallel parsing**

However, you can parse multiple files in parallel:

```rust
use rayon::prelude::*;

pub fn parse_files_parallel(
    files: Vec<(String, String)>, // (path, content)
    language: &tree_sitter::Language
) -> Vec<ParsedFile> {
    files.par_iter()  // Parallel iterator
        .map(|(path, content)| {
            let mut parser = tree_sitter::Parser::new();
            parser.set_language(language).unwrap();
            let tree = parser.parse(content, None).unwrap();

            ParsedFile {
                path: path.clone(),
                tree,
                functions: extract_functions(&tree.root_node(), content),
            }
        })
        .collect()
}
```

**Caveats:**
- Each thread needs its own Parser instance (Parsers are not thread-safe)
- Memory usage increases with thread count
- Best for I/O-bound workloads (reading files from disk)

**Web Workers (Browser):**

```javascript
// Use Web Workers for parallel parsing in browser
async function parseFilesParallel(files) {
    const numWorkers = navigator.hardwareConcurrency || 4;
    const workers = [];

    for (let i = 0; i < numWorkers; i++) {
        const worker = new Worker('parser-worker.js');
        workers.push(worker);
    }

    const chunks = chunkArray(files, numWorkers);
    const results = await Promise.all(
        chunks.map((chunk, i) =>
            workers[i].parseFiles(chunk)
        )
    );

    return results.flat();
}
```

### 5.2 Caching Parsed ASTs

**Incremental Parsing - Tree-sitter's Superpower:**

Tree-sitter's key advantage is incremental parsing:
- Reuses unchanged portions of the syntax tree
- Only reparses modified sections
- 40-50% faster for reparses vs full parses

**Implementation:**

```rust
use std::collections::HashMap;
use std::sync::{Arc, Mutex};

pub struct ParseCache {
    cache: Arc<Mutex<HashMap<String, CachedParse>>>,
}

#[derive(Clone)]
struct CachedParse {
    tree: tree_sitter::Tree,
    version: usize,  // File version/hash
    parsed_at: std::time::Instant,
}

impl ParseCache {
    pub fn parse_or_update(
        &self,
        path: &str,
        content: &str,
        language: &tree_sitter::Language
    ) -> tree_sitter::Tree {
        let hash = hash_content(content);
        let mut cache = self.cache.lock().unwrap();

        if let Some(cached) = cache.get(path) {
            if cached.version == hash {
                // Cache hit - reuse tree
                return cached.tree.clone();
            }

            // Content changed - incremental update
            let old_tree = &cached.tree;
            let mut parser = tree_sitter::Parser::new();
            parser.set_language(language).unwrap();

            // Incremental parse
            let new_tree = parser.parse(content, Some(old_tree)).unwrap();

            cache.insert(path.to_string(), CachedParse {
                tree: new_tree.clone(),
                version: hash,
                parsed_at: std::time::Instant::now(),
            });

            return new_tree;
        }

        // Not in cache - full parse
        let mut parser = tree_sitter::Parser::new();
        parser.set_language(language).unwrap();
        let tree = parser.parse(content, None).unwrap();

        cache.insert(path.to_string(), CachedParse {
            tree: tree.clone(),
            version: hash,
            parsed_at: std::time::Instant::now(),
        });

        tree
    }
}

fn hash_content(content: &str) -> usize {
    use std::collections::hash_map::DefaultHasher;
    use std::hash::{Hash, Hasher};

    let mut hasher = DefaultHasher::new();
    content.hash(&mut hasher);
    hasher.finish() as usize
}
```

**LRU Eviction:**

```rust
use lru::LruCache;

pub struct ParseCache {
    cache: Mutex<LruCache<String, CachedParse>>,
}

impl ParseCache {
    pub fn new(capacity: usize) -> Self {
        ParseCache {
            cache: Mutex::new(LruCache::new(capacity)),
        }
    }

    // ... rest of implementation
}
```

### 5.3 Incremental Updates (Re-parse Only Changed Files)

**File Watching Pattern:**

```rust
use notify::{Watcher, RecursiveMode, watcher};
use std::sync::mpsc::channel;

pub struct IncrementalIndexer {
    cache: ParseCache,
    language: tree_sitter::Language,
}

impl IncrementalIndexer {
    pub fn watch_and_update(&mut self, repo_path: &str) {
        let (tx, rx) = channel();

        let mut watcher = watcher(tx, std::time::Duration::from_millis(200))
            .expect("Failed to create watcher");

        watcher.watch(repo_path, RecursiveMode::Recursive)
            .expect("Failed to watch directory");

        loop {
            match rx.recv() {
                Ok(event) => {
                    match event {
                        notify::DebouncedEvent::Create(path)
                        | notify::DebouncedEvent::Write(path)
                        | notify::DebouncedEvent::Remove(path) => {
                            // Update index for changed file
                            self.update_file(&path);
                        }
                        _ => {}
                    }
                }
                Err(e) => {
                    eprintln!("Watch error: {:?}", e);
                }
            }
        }
    }

    fn update_file(&mut self, path: &std::path::PathBuf) {
        // Read file content
        let content = std::fs::read_to_string(path)
            .unwrap_or_default();

        // Parse with incremental update
        let tree = self.cache.parse_or_update(
            path.to_str().unwrap(),
            &content,
            &self.language
        );

        // Update vector database
        self.update_vectors(path, &tree, &content);
    }
}
```

### 5.4 Memory Usage for 1M LOC Indexing

**Memory Considerations:**

| Component | Memory per 1M LOC | Total Memory |
|-----------|-------------------|--------------|
| **Parsed Trees** | ~100-200 MB | 100-200 MB |
| **AST Nodes** | ~50-100 MB | 50-100 MB |
| **Vectors (384d)** | ~1.5 GB (30K chunks @ 384 floats) | 1.5 GB |
| **Overhead** | ~50 MB | 50 MB |
| **Total** | - | **~1.7-1.9 GB** |

**Optimization Strategies:**

1. **Don't keep all trees in memory**
   ```rust
   // Parse, extract, discard
   pub fn parse_extract_discard(
       content: &str,
       language: &tree_sitter::Language
   ) -> Vec<CodeChunk> {
       let mut parser = tree_sitter::Parser::new();
       let tree = parser.parse(content, None).unwrap();
       let chunks = extract_chunks(&tree, content);
       // Tree is dropped here
       chunks
   }
   ```

2. **Stream embeddings to vector DB**
   ```rust
   pub async fn index_large_repo(
       repo_path: &str,
       batch_size: usize
   ) -> Result<usize> {
       let files = list_files(repo_path)?;

       for chunk in files.chunks(batch_size) {
           // Parse batch
           let parsed: Vec<_> = chunk.iter()
               .map(|f| parse_file(f))
               .collect();

           // Generate embeddings
           let embeddings = generate_embeddings(&parsed).await?;

           // Send to vector DB
           vector_db.insert_batch(embeddings).await?;

           // Drop parsed data
           drop(parsed);
       }

       Ok(files.len())
   }
   ```

3. **Use streaming for large files**
   ```rust
   pub fn parse_large_file_streaming(
       path: &str,
       language: &tree_sitter::Language
   ) -> impl Iterator<Item = CodeChunk> {
       let content = std::fs::read_to_string(path).unwrap();
       let chunks = chunk_file_semantically(&content, language, 512);

       chunks.into_iter()
   }
   ```

**Target Memory Usage: <100MB for 1M LOC**

To achieve this target:
- Don't store parsed trees persistently
- Stream embeddings to vector database
- Use LRU cache for recently accessed files
- Process files in batches

---

## 6. Rust Implementation

### 6.1 Recommended Tree-sitter Rust Crates

**Core Crates:**

```toml
[dependencies]
# Core Tree-sitter
tree-sitter = "0.25"           # Main library
tree-sitter-cli = "0.25"       # CLI tool (for development)

# Language Grammars
tree-sitter-typescript = "0.23"
tree-sitter-javascript = "0.25"
tree-sitter-python = "0.25"
tree-sitter-rust = "0.25"
tree-sitter-go = "0.25"
tree-sitter-java = "0.25"

# WASM Support
wasm-bindgen = "0.2"
wasm-bindgen-futures = "0.4"
serde-wasm-bindgen = "0.6"

# Utilities
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# Async (if needed)
tokio = { version = "1.0", features = ["full"] }

# Error Handling
anyhow = "1.0"
thiserror = "1.0"

# Caching
lru = "0.12"

# Concurrency
rayon = "1.10"
```

**Development Dependencies:**

```toml
[dev-dependencies]
criterion = "0.5"      # Benchmarking
proptest = "1.4"       # Property testing
quickcheck = "1.0"     # Property testing
```

### 6.2 Error Handling Patterns

**Custom Error Types:**

```rust
use thiserror::Error;

#[derive(Error, Debug)]
pub enum VantageError {
    #[error("Tree-sitter parse error: {0}")]
    ParseError(String),

    #[error("Unsupported language: {0}")]
    UnsupportedLanguage(String),

    #[error("IO error: {0}")]
    IoError(#[from] std::io::Error),

    #[error("WASM error: {0}")]
    WasmError(String),

    #[error("Chunk size exceeded: {actual} > {max}")]
    ChunkTooLarge { actual: usize, max: usize },
}

// Convert to JsValue for WASM
impl From<VantageError> for wasm_bindgen::JsValue {
    fn from(error: VantageError) -> Self {
        wasm_bindgen::JsValue::from_str(&error.to_string())
    }
}

// Result type alias
pub type Result<T> = std::result::Result<T, VantageError>;
```

**Usage in Functions:**

```rust
#[wasm_bindgen]
pub fn parse_code(code: &str, language: &str) -> Result<ParsedCode, JsValue> {
    let parser = create_parser(language)
        .map_err(|e| VantageError::UnsupportedLanguage(e.to_string()))?;

    let tree = parser.parse(code, None)
        .ok_or_else(|| VantageError::ParseError("Failed to parse".to_string()))?;

    Ok(extract_code_info(&tree, code))
}
```

### 6.3 Testing Strategies for Parser Code

**Unit Tests:**

```rust
#[cfg(test)]
mod tests {
    use super::*;

    fn parse_test_code(code: &str) -> tree_sitter::Tree {
        let mut parser = tree_sitter::Parser::new();
        parser.set_language(&tree_sitter_typescript::language_typescript())
            .unwrap();
        parser.parse(code, None).unwrap()
    }

    #[test]
    fn test_extract_function_name() {
        let code = r#"
            function testFunction() {
                return 42;
            }
        "#;

        let tree = parse_test_code(code);
        let functions = extract_functions(&tree.root_node(), code);

        assert_eq!(functions.len(), 1);
        assert_eq!(functions[0].name, "testFunction");
    }

    #[test]
    fn test_extract_class_with_methods() {
        let code = r#"
            class MyClass {
                method1() {}
                method2() {}
            }
        "#;

        let tree = parse_test_code(code);
        let classes = extract_classes(&tree.root_node(), code);

        assert_eq!(classes.len(), 1);
        assert_eq!(classes[0].methods.len(), 2);
    }

    #[test]
    fn test_error_recovery() {
        let code = r#"
            function broken(
                return 42;
            }
        "#;

        let tree = parse_test_code(code);
        assert!(tree.root_node().has_error());

        // Should still extract valid parts
        let functions = extract_functions(&tree.root_node(), code);
        // May extract partial function
    }
}
```

**Property-Based Tests:**

```rust
#[cfg(test)]
mod proptests {
    use super::*;
    use proptest::prelude::*;

    proptest! {
        #[test]
        fn test_roundtrip_parse(code in "\\PC*") {
            // Parse and serialize should be reversible
            if let Some(tree) = parse_code_maybe(&code) {
                let serialized = serialize_tree(&tree);
                let deserialized = deserialize_tree(&serialized);
                assert_eq!(tree, deserialized);
            }
        }

        #[test]
        fn test_chunk_size_bounds(code in "\\PC*") {
            // Chunks should not exceed max size
            let chunks = chunk_code(&code, 512, 128);
            for chunk in chunks {
                assert!(chunk.tokens <= 512 * 1.2); // 20% tolerance
            }
        }
    }
}
```

**Benchmarks:**

```rust
use criterion::{black_box, criterion_group, criterion_main, Criterion};

fn bench_parse(c: &mut Criterion) {
    let code = std::fs::read_to_string("test_data/large_file.ts")
        .unwrap();

    c.bench_function("parse_large_file", |b| {
        b.iter(|| {
            let mut parser = tree_sitter::Parser::new();
            parser.set_language(&tree_sitter_typescript::language_typescript())
                .unwrap();
            black_box(parser.parse(black_box(&code), None))
        });
    });
}

criterion_group!(benches, bench_parse);
criterion_main!(benches);
```

**Integration Tests with Corpus:**

```rust
#[test]
fn test_against_tree_sitter_corpus() {
    // Use tree-sitter's test corpus
    let corpus_path = "corpus/typescript";
    for entry in std::fs::read_dir(corpus_path).unwrap() {
        let entry = entry.unwrap();
        let content = std::fs::read_to_string(entry.path()).unwrap();

        // Parse and verify
        let tree = parse_test_code(&content);
        assert!(!tree.root_node().has_error(),
            "Failed to parse corpus file: {:?}", entry.path());
    }
}
```

### 6.4 Build Configuration for Minimal WASM Size

**Optimization Settings:**

```toml
[profile.release]
opt-level = "z"           # Optimize for size
lto = true                # Link-time optimization
codegen-units = 1         # Better optimization
strip = true              # Remove debug symbols
panic = "abort"           # Reduce binary size

[profile.release.package."*"]
opt-level = "z"           # Optimize dependencies for size too
```

**Cargo Configuration:**

```toml
# .cargo/config.toml
[build]
target = "wasm32-unknown-unknown"

[target.wasm32-unknown-unknown]
rustflags = [
    "-C", "link-arg=-s",           # Strip symbols
    "-C", "link-arg=--export-table",
    "-C", "link-arg=--import-memory",
]
```

**Conditional Compilation:**

```rust
// Exclude debug code in release
#[cfg(debug_assertions)]
fn debug_print(msg: &str) {
    println!("{}", msg);
}

#[cfg(not(debug_assertions))]
fn debug_print(_msg: &str) {
    // No-op in release
}
```

**WASM-Specific Optimizations:**

```rust
// Use #[wasm_bindgen] judiciously
// Each exported function adds overhead

#[wasm_bindgen]
pub struct VantageIndexer {
    // Internal state
}

// Export only necessary methods
#[wasm_bindgen]
impl VantageIndexer {
    #[wasm_bindgen(constructor)]
    pub fn new() -> Self { /* ... */ }

    #[wasm_bindgen]
    pub fn index(&mut self, code: &str) -> JsValue { /* ... */ }

    // Don't export helper methods
    fn helper(&self) -> /* ... */ { /* ... */ }
}
```

**Expected WASM Size:**
- Base Tree-sitter: ~200 KB
- Language grammars: ~50-100 KB each
- Vantage code: ~50-100 KB
- **Total**: ~500 KB - 1 MB (with all languages)

---

## 7. Recommendations for Vantage Implementation

### 7.1 Architecture Recommendations

**Phase 1: MVP (Indexer Only)**

```
vantage-indexer/
├── Cargo.toml
├── src/
│   ├── lib.rs              # WASM exports
│   ├── parser.rs           # Parser wrapper
│   ├── languages.rs        # Language registry
│   ├── extractor.rs        # AST extraction
│   ├── chunker.rs          # Code chunking
│   └── error.rs            # Error types
└── grammars/               # Language grammars
    ├── typescript/
    ├── javascript/
    ├── python/
    ├── rust/
    ├── go/
    └── java/
```

**Key Design Decisions:**

1. **Single WASM Module**: Include all language grammars in one module
   - Simpler deployment
   - Faster loading (single fetch)
   - Trade-off: larger initial download

2. **Streaming Architecture**: Parse, extract, emit, discard
   - Minimize memory usage
   - Process files in batches
   - Stream to vector database

3. **Incremental Updates**: Use Tree-sitter's incremental parsing
   - Cache parse trees
   - Re-parse only changed files
   - Watch for file changes

### 7.2 Implementation Roadmap

**Sprint 1: Core Parser (Week 1)**
- [ ] Set up Rust project with wasm-pack
- [ ] Implement basic parser wrapper
- [ ] Add TypeScript grammar
- [ ] Create WASM bindings
- [ ] Write basic tests

**Sprint 2: AST Extraction (Week 1-2)**
- [ ] Implement function extraction
- [ ] Implement class extraction
- [ ] Preserve line numbers
- [ ] Extract signatures
- [ ] Add error recovery

**Sprint 3: Code Chunking (Week 2)**
- [ ] Implement semantic chunking
- [ ] Add token estimation
- [ ] Implement overlap
- [ ] Handle large functions
- [ ] Add chunk metadata

**Sprint 4: Multi-Language Support (Week 2-3)**
- [ ] Add JavaScript grammar
- [ ] Add Python grammar
- [ ] Add Rust grammar
- [ ] Add Go grammar
- [ ] Add Java grammar
- [ ] Test monorepo scenarios

**Sprint 5: Performance Optimization (Week 3)**
- [ ] Implement caching
- [ ] Add incremental parsing
- [ ] Optimize WASM size
- [ ] Benchmark performance
- [ ] Memory profiling

**Sprint 6: Integration (Week 3-4)**
- [ ] Integrate with Node.js proxy
- [ ] Add embedding generation
- [ ] Stream to vector DB
- [ ] End-to-end testing
- [ ] Documentation

### 7.3 Potential Pitfalls and How to Avoid Them

**Pitfall 1: Memory Leaks in WASM**

**Problem**: WASM memory grows unbounded
**Solution**:
```javascript
// Explicit cleanup
let parser = null;
function cleanup() {
    if (parser) {
        parser.free();
        parser = null;
    }
}

// Or use WeakRef
const parserWeakRef = new WeakRef(parser);
```

**Pitfall 2: Slow Parsing of Large Files**

**Problem**: Files >1MB take >1s to parse
**Solution**:
```rust
// Skip very large files
const MAX_FILE_SIZE: usize = 1_000_000; // 1MB

if content.len() > MAX_FILE_SIZE {
    return Err(VantageError::FileTooLarge);
}

// Or parse in chunks
fn parse_large_file_chunks(content: &str) -> Vec<CodeChunk> {
    // Split by top-level declarations
    // Parse each chunk separately
}
```

**Pitfall 3: Grammar Incompatibilities**

**Problem**: Different grammars have different node types
**Solution**:
```rust
// Use trait for abstraction
pub trait LanguageAdapter {
    fn extract_functions(&self, root: &Node, source: &str) -> Vec<FunctionInfo>;
    fn extract_classes(&self, root: &Node, source: &str) -> Vec<ClassInfo>;
    fn get_query(&self) -> &Query;
}

// Implement for each language
struct TypeScriptAdapter;
impl LanguageAdapter for TypeScriptAdapter {
    // ...
}
```

**Pitfall 4: Error Nodes Break Extraction**

**Problem**: Syntax errors cause extraction to fail
**Solution**:
```rust
// Always check for errors
fn extract_with_errors(root: &Node, source: &str) -> Vec<CodeElement> {
    let mut elements = Vec::new();

    // Skip error nodes
    let mut cursor = root.walk();
    for child in root.children(&mut cursor) {
        if !child.is_error() && !child.is_missing() {
            elements.extend(extract_from_node(&child, source));
        }
    }

    elements
}
```

**Pitfall 5: Token Count Inaccuracy**

**Problem**: Rough token estimation leads to poor chunking
**Solution**:
```rust
// Use more accurate estimation
fn estimate_tokens(text: &str) -> usize {
    // Count keywords, identifiers, operators
    let keywords = count_keywords(text);
    let identifiers = count_identifiers(text);
    let operators = count_operators(text);

    keywords + identifiers + operators
}

// Or use tokenizer (more accurate, slower)
use tiktoken_rs::tiktoken::cl100k_base;

fn count_tokens_accurate(text: &str) -> usize {
    let bpe = cl100k_base().unwrap();
    let tokens = bpe.encode(text, None);
    tokens.len()
}
```

### 7.4 Performance Targets

**Benchmarks to Achieve:**

| Metric | Target | How to Measure |
|--------|--------|----------------|
| **Parse 1K LOC** | <10ms | Criterion benchmark |
| **Parse 100K LOC** | <1s | Integration test |
| **Memory (100K LOC)** | <50MB | Heap profiling |
| **WASM size** | <1MB | Build output |
| **Chunking overhead** | <5% | Benchmark vs manual |

**Performance Testing:**

```rust
#[cfg(test)]
mod perf_tests {
    use super::*;
    use std::time::Instant;

    #[test]
    fn test_parse_100k_loc() {
        let code = generate_test_code(100_000);
        let start = Instant::now();

        let chunks = chunk_code(&code, 512, 128);

        let duration = start.elapsed();
        assert!(duration.as_secs() < 1, "Parsing took too long: {:?}", duration);
    }

    #[test]
    fn test_memory_usage() {
        let code = generate_test_code(100_000);
        let memory_before = get_memory_usage();

        let _chunks = chunk_code(&code, 512, 128);

        let memory_after = get_memory_usage();
        let used = memory_after - memory_before;

        assert!(used < 50 * 1024 * 1024, "Used too much memory: {} MB", used / 1024 / 1024);
    }
}
```

---

## 8. Code Examples

### 8.1 Complete Parser Implementation

```rust
use tree_sitter::Parser;
use wasm_bindgen::prelude::*;

#[wasm_bindgen]
pub struct VantageParser {
    parser: Parser,
    language_name: String,
}

#[wasm_bindgen]
impl VantageParser {
    #[wasm_bindgen(constructor)]
    pub fn new(language: &str) -> Result<VantageParser, JsValue> {
        let mut parser = Parser::new();

        let language = match language {
            "typescript" => tree_sitter_typescript::language_typescript(),
            "javascript" => tree_sitter_javascript::language_javascript(),
            "python" => tree_sitter_python::language_python(),
            "rust" => tree_sitter_rust::language_rust(),
            "go" => tree_sitter_go::language_go(),
            "java" => tree_sitter_java::language_java(),
            _ => return Err(JsValue::from_str("Unsupported language")),
        };

        parser.set_language(&language)
            .map_err(|e| JsValue::from_str(&format!("Failed to set language: {:?}", e)))?;

        Ok(VantageParser {
            parser,
            language_name: language.to_string(),
        })
    }

    #[wasm_bindgen]
    pub fn parse(&mut self, code: &str) -> Result<ParseResult, JsValue> {
        let tree = self.parser.parse(code, None)
            .ok_or_else(|| JsValue::from_str("Failed to parse code"))?;

        let root = tree.root_node();
        let has_errors = root.has_error();

        let functions = extract_functions(&root, code);
        let classes = extract_classes(&root, code);
        let chunks = chunk_code(&root, code, 512, 128);

        Ok(ParseResult {
            has_errors,
            functions: serde_wasm_bindgen::to_value(&functions)?,
            classes: serde_wasm_bindgen::to_value(&classes)?,
            chunks: serde_wasm_bindgen::to_value(&chunks)?,
        })
    }

    #[wasm_bindgen]
    pub fn free(&mut self) {
        // Clean up if needed
    }
}

#[derive(serde::Serialize)]
pub struct ParseResult {
    has_errors: bool,
    functions: Vec<FunctionInfo>,
    classes: Vec<ClassInfo>,
    chunks: Vec<CodeChunk>,
}
```

### 8.2 Chunker Implementation

```rust
pub struct CodeChunker {
    target_size: usize,
    overlap: usize,
    max_size: usize,
}

impl CodeChunker {
    pub fn new(target_size: usize, overlap: usize, max_size: usize) -> Self {
        Self {
            target_size,
            overlap,
            max_size,
        }
    }

    pub fn chunk(
        &self,
        root: &tree_sitter::Node,
        source: &str
    ) -> Vec<CodeChunk> {
        let mut chunks = Vec::new();
        let mut current_chunk = CodeChunk::default();
        let mut current_size = 0;

        // Extract top-level declarations
        let decls = self.extract_top_level_declarations(root, source);

        for decl in decls {
            let decl_size = self.estimate_tokens(&decl.text);

            if decl_size > self.max_size {
                // Split large declaration
                let sub_chunks = self.split_large_declaration(&decl, source);
                chunks.extend(sub_chunks);
                continue;
            }

            if current_size + decl_size > self.target_size && !current_chunk.is_empty() {
                chunks.push(current_chunk.clone());
                current_chunk = CodeChunk::default();
                current_size = 0;
            }

            current_chunk.declarations.push(decl);
            current_size += decl_size;
        }

        if !current_chunk.is_empty() {
            chunks.push(current_chunk);
        }

        chunks
    }

    fn split_large_declaration(
        &self,
        decl: &Declaration,
        source: &str
    ) -> Vec<CodeChunk> {
        // For now, simple token-based splitting
        // TODO: Implement AST-aware splitting
        let text = &decl.text;
        let chunks = Vec::new();
        let mut start = 0;

        while start < text.len() {
            let end = (start + self.target_size * 4).min(text.len());
            let chunk_text = &text[start..end];
            chunks.push(CodeChunk {
                text: chunk_text.to_string(),
                tokens: self.estimate_tokens(chunk_text),
                ..Default::default()
            });
            start = end - (self.overlap * 4);
        }

        chunks
    }

    fn estimate_tokens(&self, text: &str) -> usize {
        // Rough estimation: 4 chars per token
        text.len() / 4
    }
}
```

---

## 9. References and Further Reading

### 9.1 Official Documentation

- [Tree-sitter Official Documentation](https://tree-sitter.github.io/)
- [Tree-sitter Query Syntax](https://tree-sitter.github.io/tree-sitter/using-parsers/queries/1-syntax.html)
- [wasm-bindgen Guide](https://rustwasm.github.io/docs/wasm-bindgen/print.html)
- [wasm-pack Documentation](https://rustwasm.github.io/docs/wasm-pack/)

### 9.2 Academic Papers

- [Analyzing the Performance of WebAssembly vs. Native Code](https://www.usenix.org/system/files/atc19-jangda.pdf) - USENIX ATC 2019
- [Fast Incremental PEG Parsing](https://people.seas.harvard.edu/~chong/pubs/gpeg_sle21.pdf)
- [cAST: Enhancing Code Retrieval-Augmented Generation](https://arxiv.org/html/2506.15655v2)

### 9.3 Blog Posts and Articles

- [Incremental Parsing Using Tree-sitter](https://tomassetti.me/incremental-parsing-using-tree-sitter/)
- [Building RAG on Codebases: Part 2](https://lancedb.com/blog/building-rag-on-codebases-part-2/)
- [AST Aware Code Chunking](https://supermemory.ai/blog/building-code-chunk-ast-aware-code-chunking/)
- [How I Built CodeRAG with Dependency Graph Using Tree-sitter](https://medium.com/@shsax/how-i-built-coderag-with-dependency-graph-using-tree-sitter-0a71867059ae)
- [Speeding up tree-sitter-haskell 50x](https://owen.cafe/posts/tree-sitter-haskell-perf/)

### 9.4 GitHub Repositories

- [tree-sitter/tree-sitter](https://github.com/tree-sitter/tree-sitter) - Main repository
- [tree-sitter-grammars](https://github.com/tree-sitter) - Language grammars
- [code-splitter](https://lib.rs/crates/code-splitter) - Rust code splitting library

### 9.5 Community Resources

- [Stack Overflow: tree-sitter](https://stackoverflow.com/questions/tagged/tree-sitter)
- [Reddit: r/tree-sitter](https://www.reddit.com/r/tree_sitter/)
- [Discord: Tree-sitter](https://discord.gg/tree-sitter)

---

## 10. Conclusion

This research confirms that **Tree-sitter + WASM is the right choice for Vantage's codebase indexing needs**. The technology stack provides:

- **Excellent language support** for all target languages
- **Production-ready performance** even with WASM overhead
- **Robust error recovery** for incomplete or buggy code
- **Incremental parsing** for efficient updates
- **Semantic chunking** capabilities for RAG systems

**Next Steps:**

1. Implement the core parser with TypeScript support (Sprint 1)
2. Add semantic chunking and AST extraction (Sprint 2-3)
3. Integrate with Cloudflare Workers AI for embeddings (Sprint 4)
4. Build the vector database sync (Sprint 5)
5. Deploy and test on large codebases (Sprint 6)

**Success Criteria:**

- ✅ Index 100K LOC in <30 seconds
- ✅ Memory usage <100MB for 1M LOC
- ✅ Support all 6 target languages
- ✅ Handle syntax errors gracefully
- ✅ Generate chunks suitable for vector embeddings

---

**Document Status**: Complete
**Last Updated**: 2026-01-13
**Next Review**: After Sprint 3 implementation
